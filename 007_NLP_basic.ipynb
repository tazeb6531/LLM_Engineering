{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Natural Language Processing -- Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### spaCy Basics\n",
    "\n",
    "**spaCy** (https://spacy.io/) is an open-source Python library that ***parses*** and ***understands*** large volumes of text. Separate models are available that cater to specific languages (English, French, German, etc.). It uses a pipeline-based architecture.\n",
    "\n",
    "**It Provides a pretrained models for tasks:**\n",
    "* Tokenizer ‚Äì Splits text into tokens.\n",
    "* Tagger ‚Äì Assigns part-of-speech (POS) tags.\n",
    "* Parser ‚Äì Analyzes grammatical structure (dependency parsing).\n",
    "* Named Entity Recognizer (NER) ‚Äì Identifies entities like names, dates, and locations.\n",
    "* Lemmatizer ‚Äì Converts words to their base form (e.g., running ‚Üí run).\n",
    "* Text Classifier (if included) ‚Äì Categorizes text into predefined labels.\n",
    "\n",
    "#### Installation and Setup\n",
    "\n",
    "Installation is a two-step process. First, install spaCy using either conda or pip. Next, download the specific model you want, based on language.<br> For more info visit https://spacy.io/usage/\n",
    "\n",
    "#### 1. From the command line or terminal:\n",
    "> `conda install -c conda-forge spacy`\n",
    "> <br>*or*<br>\n",
    "> `pip install -U spacy`\n",
    "\n",
    "> #### Alternatively you can create a virtual environment:\n",
    "> `conda create -n spacyenv python=3 spacy=2`\n",
    "\n",
    "#### 2. Next, also from the command line (you must run this as admin or use sudo):\n",
    "\n",
    "> `python -m spacy download en`\n",
    "\n",
    "> #### If successful, you should see a message like:\n",
    "\n",
    "> **`Linking successful`**<br>\n",
    "> `    C:\\Anaconda3\\envs\\spacyenv\\lib\\site-packages\\en_core_web_sm -->`<br>\n",
    "> `    C:\\Anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\data\\en`<br>\n",
    "> ` `<br>\n",
    "> `    You can now load the model via spacy.load('en')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario: Automating Resume Screening for Job Applications\n",
    "A company receives thousands of resumes and wants to automate the initial screening process using **spaCy**. The ***NLP pipeline*** can help extract useful information from candidate resumes and categorize them based on job relevance.\n",
    "\n",
    "#### How Each Component is Used:\n",
    "* **Tokenizer** ‚Äì Splits the resume text into individual words/tokens.\n",
    "\n",
    "    Example: ‚ÄúExperienced Python developer with 5 years of experience‚Äù ‚Üí [\"Experienced\", \"Python\", \"developer\", \"with\", \"5\", \"years\", \"of\", \"experience\"]\n",
    "\n",
    "* **Tagger (POS tagging) ‚Äì** Identifies parts of speech to understand key terms.\n",
    "    Example: \"Python\" (NOUN), \"developing\" (VERB), \"experienced\" (ADJ).\n",
    "\n",
    "* **Parser (Dependency Parsing)** ‚Äì Analyzes the grammatical structure to understand relationships between words.\n",
    "    Example: Identifies that ‚Äú5 years‚Äù modifies ‚Äúexperience,‚Äù meaning the candidate has 5 years of experience.\n",
    "\n",
    "* **Named Entity Recognizer (NER)** ‚Äì Extracts key entities like names, locations, skills, and dates.\n",
    "    Example:\n",
    "\n",
    "    John Doe (PERSON)\n",
    "\n",
    "    Python, Machine Learning (SKILLS)\n",
    "\n",
    "    Microsoft (ORG)\n",
    "\n",
    "    New York (GPE ‚Äì Geo-Political Entity)\n",
    "\n",
    "* **Lemmatizer ‚Äì** Converts words into their root form for better matching.\n",
    "    Example: \"Developing\" ‚Üí \"Develop\", \"Worked\" ‚Üí \"Work\".\n",
    "\n",
    "* **Text Classifier ‚Äì** Categorizes resumes into predefined job roles based on keywords and extracted information.\n",
    "    Example: If the resume contains \"Python, TensorFlow, Machine Learning,\" it is classified under \"Data Scientist\"; if it includes \"Java, Spring Boot,\" it is classified under \"Backend Developer\".\n",
    "\n",
    "#### Outcome:\n",
    "The company can automatically filter and rank resumes based on skills, experience, and job relevance, saving HR teams hours of manual screening.\n",
    "\n",
    "Would you like a code example for implementing this scenario in spaCy? üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end Resume Parsing & Analysis Project using spaCy \n",
    "\n",
    "- ‚úÖ Step 1: Data Collection & Preprocessing\n",
    "- ‚úÖ Step 2: Applying NLP Pipeline (Tokenizer, POS Tagging, NER, Lemmatization, Parsing, Classification, etc.)\n",
    "- ‚úÖ Step 3: Extracting Key Information (Name, Skills, Experience, Education, etc.)\n",
    "- ‚úÖ Step 4: Resume Categorization (Job Role Classification using ML/NLP)\n",
    "- ‚úÖ Step 5: Storing & Analyzing Results (JSON/Database, visualization, ranking resumes, etc.)\n",
    "- ‚úÖ Step 6: Deploying a Simple Web App (Streamlit or Flask) for Uploading Resumes\n",
    "\n",
    "\n",
    "***I'll create a structured code framework for Resume Parsing using spaCy, which includes:***\n",
    "\n",
    "* Data Ingestion: Uploading resumes (text/PDF parsing).\n",
    "* Text Preprocessing: Cleaning and tokenizing text.\n",
    "* NLP Pipeline Processing: Applying spaCy to extract important details.\n",
    "* Information Extraction: Identifying names, skills, education, work experience.\n",
    "* Resume Classification: Categorizing into predefined job roles using NLP & ML.\n",
    "* Visualization & Analysis: Storing data, ranking resumes based on relevancy.\n",
    "* Deployment: A simple UI for uploading and analyzing resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pdfplumber # For PDF text extraction \n",
    "import re # For regular expressions\n",
    "import json\n",
    "from collections import Counter\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.pipeline.textcat import Config, single_label_cnn_config\n",
    "\n",
    "# Load pre-trained SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\" # Initialize empty string to store text\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages: # Iterate through each page\n",
    "            text += page.extract_text() + \"\\n\" # Extract text from each page and append to text variable \n",
    "    return text.strip() # Return the cleaned text after stripping leading/trailing whitespace\n",
    "\n",
    "# Function to preprocess text (cleaning)\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "    return text.lower()\n",
    "\n",
    "# Function to extract named entities (NER)\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = {ent.label_: ent.text for ent in doc.ents}\n",
    "    return entities\n",
    "\n",
    "# Function to extract skills using keyword matching\n",
    "def extract_skills(text):\n",
    "    skills = [\"python\", \"machine learning\", \"data science\", \"sql\", \"java\", \"deep learning\", \"nlp\"]\n",
    "    found_skills = [skill for skill in skills if skill.lower() in text.lower()]\n",
    "    return found_skills\n",
    "\n",
    "# Function to classify resumes into job roles\n",
    "def classify_resume(text):\n",
    "    categories = {\n",
    "        \"Data Scientist\": [\"machine learning\", \"python\", \"data science\", \"deep learning\"],\n",
    "        \"Software Engineer\": [\"java\", \"spring boot\", \"microservices\", \"docker\"],\n",
    "        \"Business Analyst\": [\"excel\", \"business analysis\", \"sql\", \"data visualization\"]\n",
    "    }\n",
    "    \n",
    "    scores = {role: sum(1 for skill in skills if skill in text.lower()) for role, skills in categories.items()}\n",
    "    return max(scores, key=scores.get) if max(scores.values()) > 0 else \"Unknown\"\n",
    "\n",
    "# Function to process resume text and extract relevant details\n",
    "def process_resume(pdf_path):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    cleaned_text = clean_text(text)\n",
    "    entities = extract_entities(cleaned_text)\n",
    "    skills = extract_skills(cleaned_text)\n",
    "    job_role = classify_resume(cleaned_text)\n",
    "    \n",
    "    result = {\n",
    "        \"Extracted Text\": text,       \n",
    "        \"Entities\": entities,\n",
    "        \"Skills\": skills,\n",
    "        \"Predicted Job Role\": job_role\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":    \n",
    "    pdf_path = \"C:/Users/tazeb/OneDrive/AtomicHabit/LLM Engineering/LLM_Engineering/TA_resume.pdf\" \n",
    "    result = process_resume(pdf_path)\n",
    "    #print(json.dumps(result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Extracted Text': \"TAZEB ABERA\\n8801 Edna Place Rowlett, TX 75089\\nPhone: (214)430-2241\\nEmail: tazabera@gmail.com\\nWebsite: https://mydatascienceenthusiast.com/\\nLinked Page: https://www.linkedin.com/in/tazeb-abera\\nGitHub: https://github.com/tazeb6531\\nProfessional Summary\\nInnovative Senior Data Scientist with extensive experience delivering impactful AI-driven solutions across healthcare,\\nmanufacturing, business operations, and engineering materials sectors. At Celanese, successfully applied advanced machine\\nlearning techniques to refine search engine accuracy and streamline competitor analysis, achieved a 60% accuracy boost,\\n40% faster search times, and 15% reduction in development process time. Proficient in integrating advanced tools like\\nElasticsearch, Azure GenAI, and Snowflake Cortex to foster innovation and enhance decision-making processes. Skilled in\\nNLP, deep learning, predictive modeling, and generative AI, with a focus on improving operational efficiency and driving\\nstrategic insights.\\nDemonstrated leadership in managing cross-functional teams to deliver scalable cloud-based pipelines, Streamlit\\nDashboards, and custom analytics platforms for organizations like NYCHHC, Samsung, Change Healthcare, and QORVO.\\nExpertise spans EPIC healthcare data, cloud computing, and advanced programming languages, including Python, SQL,\\nand DevOps tools. Holds advanced degrees in Data Science, Machine Learning, and Engineering, and is currently pursuing\\na PhD. Dedicated to utilizing advanced technologies to solve complex problems, foster innovation, and deliver measurable\\nbusiness outcomes.\\nEducation Background\\nNorthCentral University -- PhD in Data Science (not awarded)\\nSouthern Methodist University ‚Äì Master of Science in Data Science.\\nBahir Dar University ‚Äì Master of Science in Sustainable Energy Engineering.\\nJimma University ‚Äì bachelor‚Äôs degree in computer science.\\nProfessional Experience\\nSenior Data Scientist 06/2024 to Present New York City Health + Hospitals (NYCHHC) - Remote\\n‚Ä¢ Led development of Generative AI models to streamline hospital billing (HB) and professional billing (PB) transaction\\nanalysis.\\n‚Ä¢ Built Eligibility Prediction models leveraging EPIC healthcare data to improve operational efficiency.\\n‚Ä¢ Developed RAG (Retrieval-Augmented Generation) models to extract and analyze insights from unstructured medical\\nnotes.\\n‚Ä¢ Integrated Snowflake Cortex with Snowflake data warehouses to implement scalable and efficient AI-powered\\npipelines.\\n‚Ä¢ Designed Streamlit Dashboards for real-time data visualization and encounter inspection, enhancing charge capture and\\nidentifying anomalies.\\n‚Ä¢ Reduced revenue leakage between HB and PB transactions through semantic analysis.\\n‚Ä¢ Partnered with cross-functional teams to align AI and data solutions with NYCHHC's clinical and financial workflows.\\n‚Ä¢ Automated complex SQL-based data extraction pipelines for performance optimization.\\nSenior Data Scientist 07/2021 to 05/2024 Celanese ‚Äì Irving, TX\\n‚Ä¢ Coordinated a skilled team in Agile development of a sophisticated AI-driven search engine, utilizing advanced GenAI,\\nclustering algorithms, and various machine learning models for optimal performance.\\n‚Ä¢ Integration of Advanced Tools: Worked extensively with Elasticsearch and Azure GenAI, integrating them with NER\\nto enhance search capabilities and data analysis.\\n‚Ä¢ Analytics and Workflow Optimization: Enhanced operational efficiency through data-driven strategies and optimized\\nworkflows.\\n‚Ä¢ Data Cleaning and Preparation: Conducted thorough data cleaning, feature engineering, and exploratory data analysis\\n(EDA) to ensure high-quality data for analysis.\\n‚Ä¢ Predictive Modeling: Developed advanced predictive ML models to identify competitor producers in the engineering\\nmaterials sector, providing strategic insights.\\n‚Ä¢ AI-Driven Search Engine Development: Led the creation of an AI-driven search engine with advanced similarity\\nsearch and entity recognition techniques, improving data retrieval accuracy.\\n‚Ä¢ NLP Implementation: Applied NLP techniques, including entity recognition, to improve search engine operations and\\nenhance data retrieval accuracy.\\n‚Ä¢ Deep Learning Applications: Utilized deep learning methodologies to develop sophisticated models and solutions,\\nadvancing the company‚Äôs AI capabilities.\\nData Science Part time 07 /2019 to12/2020 Change Healthcare‚Äì Dallas, TX\\n‚Ä¢ Python Scripting: Wrote scripts in Python to extract data from HTML files, ensuring efficient data retrieval and\\nprocessing.\\n‚Ä¢ Business and Medical Procedures Evaluation: Assessed business and medical treatment procedures, incorporating them\\ninto the database system for improved management and accessibility.\\n‚Ä¢ Clinical Data Integration: Coordinated with the technical team to integrate clinical data, enhancing the completeness and\\nusability of medical records.\\n‚Ä¢ Statistical Analysis: Utilized various statistical methods and tools to measure performance variables, providing critical\\ninsights into operational and treatment efficiencies.\\n‚Ä¢ Custom Reporting: Generated custom reports and created statistical control process charts to monitor and evaluate key\\nmetrics.\\n‚Ä¢ Process Improvement: Suggested corrective actions to improve internal procedures and data management practices,\\ndriving continuous improvement.\\n‚Ä¢ System Design and Implementation: Designed, documented, tested, and implemented a clinical data collection system,\\nensuring robust and reliable data capture.\\nData Scientist 06/2018 to 06/2019 QORVO ‚Äì Richardson, TX\\n‚Ä¢ Developed and maintained statistical algorithms and models with the focus on big data.\\n‚Ä¢ Core team player in performing data analysis for metrics and decision-making process; directionally goal oriented to\\nbring in defined results.\\n‚Ä¢ Performed EDA and feature engineering to both inform the development of statistical models and improve model\\nperformance and flexibility.\\n‚Ä¢ Provide analysis using mathematical modeling tools to improve business processes and decisions.\\n‚Ä¢ Assist with the development of standardized reporting solutions that align metrics and drivers with the associated\\nfinancials.\\n‚Ä¢ Create dashboards and reports to regularly communicate results and monitor key metrics.\\nBusiness Analyst 12/2016 to 05/2018 Samsung ‚Äì Plano, TX\\n‚Ä¢ Understand market volatility, analyze customers‚Äô needs and/or market competitiveness to drive accuracy of future\\nmobile phone prices.\\n‚Ä¢ Reduced development costs by 25% by consolidating related products into streamlined solutions.\\n‚Ä¢ Correlation analysis for retailer business.\\n‚Ä¢ Predicting the business performance of the company.\\n‚Ä¢ Prepared interactive reports to organically feed into our reporting tools such as Tableau and R shine.\\n‚Ä¢ Experienced in developing business reports by writing complex SQL queries using views, macros, volatile and global\\ntemporary tables.\\n‚Ä¢ Experience in working on MS Access, MS Excel, and MS Power Point\\n‚Ä¢ Experienced in handling all the domain and technical interaction with application users,\\nanalyzing client business processes, documenting business requirements\\n‚Ä¢ Possess strong analytical and problem-solving skills and have quick learning curve.\\nCommitted team player and capable of working on tight project delivery schedules and\\ndeadlines.\\n‚Ä¢ Proficiency in prioritizing and multi-tasking to ensure that tasks are completed on time.\\n‚Ä¢ Demonstrate a willingness, interest, and aptitude to learn new technologies and skills.\\n‚Ä¢ Good Communication and interpersonal skills.\\nData Scientist 01/2015 to 09/2016 Power Africa|USAID ‚Äì Bahir Dar, Ethiopia\\n‚Ä¢ Led a team of over 150 people countrywide over more than 8 regional states.\\n‚Ä¢ Defined work scope procedures for lower-level managers, overcome any technical and legal challenges by partnering\\nwith government leaders under the umbrella of Sustainable Development and Poverty Reduction mission.\\n‚Ä¢ Examined Produced Energy Data, arrange results in a presentable and coherent way for upper management and\\nstakeholders.\\n‚Ä¢ Embodied a team of 27 data scientists under my organization who focused on data produced and analyzed from\\nbioenergy, wind, and solar energy.\\n‚Ä¢ Responsible for debugging the project.\\n‚Ä¢ Built user defined function (UDF) and performing various CRUD operations like create, update, read and delete.\\n‚Ä¢ Created Python scripts for merging data into MySQL database.\\n‚Ä¢ Communicating with external venders and high-level officials to resolve queries.\\n‚Ä¢ Report results and SWOT analysis report to high management body.\\n‚Ä¢ Maintain search features/data mapping diagrams.\\nPower Engineer 01/2015 to 09/2016 Organization and rehabilitation Development in Amhara Region ORDA ‚Äì\\nBahir Dar,\\n‚Ä¢ Identified and resolved abnormalities with power production equipment and processes.\\n‚Ä¢ Monitored biomass operations for compliance with regulatory requirements.\\n‚Ä¢ Oversaw a well-organized maintenance program for predictive and preventive actions.\\n‚Ä¢ Optimize financial performance.\\n‚Ä¢ Cost - profit analysis for solar panels and other equipment imported from different countries.\\n‚Ä¢ Prepare and present Project performance Report for high level officials.\\nSkills\\n‚Ä¢ Programming Languages: Python, R, JAVA, SAS, SQL, HTML, CSS.\\n‚Ä¢ Data Science Tools: PyTorch, TensorFlow, Keras, SciPy, Pandas, NumPy, Jupyter Notebook, Data Bricks.\\n‚Ä¢ Data Visualization: Matplotlib, Seaborn, Tableau, Power BI.\\n‚Ä¢ Cloud Platforms and DevOps: Azure, AWS, Snowflake, Docker, Kubernetes, GitHub, CI/CD.\\n‚Ä¢ Machine Learning & AI: GenAI, LangChain, RAG, NLP, Hugging Face, Llama2, Transformers, BERT,\\nSnowflake Cortex.\\n‚Ä¢ Big Data & Databases: Apache Spark, Hadoop, Airflow, MySQL, SQL Server, Snowflake, NoSQL (Cassandra),\\nSSIS, SSRS, ETL.\\n‚Ä¢ Statistical Tools: MATLAB, SAS, Statistical Modeling, Predictive Analytics.\\n‚Ä¢ Soft Skills: Problem Solving, Project Management, Agile Methodologies.\",\n",
       " 'Entities': {'PERSON': 'keras scipy',\n",
       "  'DATE': '012015',\n",
       "  'ORG': 'llama2',\n",
       "  'CARDINAL': '27',\n",
       "  'GPE': 'ethiopia',\n",
       "  'NORP': 'orda'},\n",
       " 'Skills': ['python',\n",
       "  'machine learning',\n",
       "  'data science',\n",
       "  'sql',\n",
       "  'java',\n",
       "  'deep learning',\n",
       "  'nlp'],\n",
       " 'Predicted Job Role': 'Data Scientist'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pipeline\n",
    "When we run `nlp`, our text enters a *processing pipeline* that first breaks down the text and then performs a series of operations to tag, parse and describe the data.   Image source: https://spacy.io/usage/spacy-101#pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnlp\u001b[49m\u001b[38;5;241m.\u001b[39mpipeline)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(nlp\u001b[38;5;241m.\u001b[39mpipe_names)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "print(nlp.pipeline)\n",
    "print(\"\\n\")\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spaCy, the NLP pipeline consists of several **trainable** components that process text sequentially. These include:\n",
    "* **tok2vec**, which generates vector representations for tokens, \n",
    "* **tagger**, which assigns part-of-speech (POS) tags, \n",
    "* **parser**, which analyzes sentence structure through dependency parsing, \n",
    "* **NER**, which detects named entities like names and organizations, \n",
    "* **attribute_ruler**, which refines POS and morphology attributes, and \n",
    "* **Lemmatizer**, which converts words to their base forms. \n",
    "\n",
    "While these components are explicitly listed in nlp.pipe_names, some core functionalities like **tokenization** always run first but are not considered trainable components. The pipeline ensures efficient text processing by automatically passing data through these components in sequence. üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Part-of-Speech (POS) Tagging in spaCy\n",
    "\n",
    "In **spaCy**, **Part-of-Speech (POS) tagging** assigns grammatical labels (e.g., noun, verb, adjective) to each token in a text. The **`tagger`** component in spaCy‚Äôs pipeline is responsible for POS tagging, leveraging pre-trained statistical models for accuracy. \n",
    "\n",
    "##### üîπ How to Access POS Tags:\n",
    "- `token.pos_` ‚Üí General POS category (e.g., `NOUN`, `VERB`, `ADJ`).\n",
    "- `token.tag_` ‚Üí Detailed POS tag (specific to the language model).\n",
    "- `spacy.explain(token.pos_)` ‚Üí Get explanations for POS tags.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"John is learning Python.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, \"‚Üí\", token.pos_, \"(\", spacy.explain(token.pos_), \")\")\n",
    "```\n",
    "\n",
    "\n",
    "* The challenge of correctly identifying parts of speech is summed up nicely in the [spaCy docs](https://spacy.io/usage/linguistic-features):\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"margin: 20px\">Processing raw text intelligently is difficult: most words are rare, and it's common for words that look completely different to mean almost the same thing. The same words in a different order can mean something completely different. Even splitting text into useful word-like units can be difficult in many languages. While it's possible to solve some problems starting from only the raw characters, it's usually better to use linguistic knowledge to add useful information. That's exactly what spaCy is designed to do: you put in raw text, and get back a **Doc** object, that comes with a variety of annotations.</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumped over the lazy dog's back.\n",
      "\n",
      "jumped VERB VBD verb, past tense\n"
     ]
    }
   ],
   "source": [
    "# Create a simple Doc object\n",
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back.\")\n",
    "print(doc.text)\n",
    "print()\n",
    "print(doc[4].text, doc[4].pos_, doc[4].tag_, spacy.explain(doc[4].tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The        DET      DT     determiner\n",
      "quick      ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "brown      ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "fox        NOUN     NN     noun, singular or mass\n",
      "jumped     VERB     VBD    verb, past tense\n",
      "over       ADP      IN     conjunction, subordinating or preposition\n",
      "the        DET      DT     determiner\n",
      "lazy       ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "dog        NOUN     NN     noun, singular or mass\n",
      "'s         PART     POS    possessive ending\n",
      "back       NOUN     NN     noun, singular or mass\n",
      ".          PUNCT    .      punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'{token.text:{10}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coarse-grained Part-of-speech Tags\n",
    "Every token is assigned a POS Tag from the following list:\n",
    "\n",
    "<table><tr><th>POS</th><th>DESCRIPTION</th><th>EXAMPLES</th></tr>\n",
    "    \n",
    "<tr><td>ADJ</td><td>adjective</td><td>*big, old, green, incomprehensible, first*</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>*in, to, during*</td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>*very, tomorrow, down, where, there*</td></tr>\n",
    "<tr><td>AUX</td><td>auxiliary</td><td>*is, has (done), will (do), should (do)*</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>CCONJ</td><td>coordinating conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>*a, an, the*</td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>*psst, ouch, bravo, hello*</td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>*girl, cat, tree, air, beauty*</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>*1, 2017, one, seventy-seven, IV, MMXIV*</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>*'s, not,*</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>*I, you, he, she, myself, themselves, somebody*</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>*Mary, John, London, NATO, HBO*</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>*., (, ), ?*</td></tr>\n",
    "<tr><td>SCONJ</td><td>subordinating conjunction</td><td>*if, while, that*</td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>*$, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù*</td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>*run, runs, running, eat, ate, eating*</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>*sfpksdpsxmsa*</td></tr>\n",
    "<tr><td>SPACE</td><td>space</td></tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with POS Tags\n",
    "In the English language, the same string of characters can have different meanings, even within the same sentence. For this reason, morphology is important. **spaCy** uses machine learning algorithms to best predict the use of a token in a sentence. Is *\"I read books on NLP\"* present or past tense? Is *wind* a verb or a noun?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read       VERB     VBP    verb, non-3rd person singular present\n",
      "Look at this to see the difference o consfusing tags\n",
      "read       VERB     VBD    verb, past tense\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'I read books on NLP.')\n",
    "r = doc[1]\n",
    "\n",
    "print(f'{r.text:{10}} {r.pos_:{8}} {r.tag_:{6}} {spacy.explain(r.tag_)}')\n",
    "print(\"Look at this to see the difference o consfusing tags\")\n",
    "\n",
    "doc = nlp(u'I read a book on NLP.')\n",
    "r = doc[1]\n",
    "\n",
    "print(f'{r.text:{10}} {r.pos_:{8}} {r.tag_:{6}} {spacy.explain(r.tag_)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting POS Tags\n",
    "The `Doc.count_by()` method accepts a specific token attribute as its argument, and returns a frequency count of the given attribute as a dictionary object. Keys in the dictionary are the integer values of the given attribute ID, and values are the frequency. Counts of zero are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{90: 2, 84: 3, 92: 3, 100: 1, 85: 1, 94: 1, 97: 1}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back.\")\n",
    "# Count the frequencies of different coarse-grained POS tags:\n",
    "POS_counts = doc.count_by(spacy.attrs.POS)\n",
    "POS_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't very helpful until you decode the attribute ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADJ'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vocab[84].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a frequency list of POS tags from the entire document\n",
    "Since `POS_counts` returns a dictionary, we can obtain a list of keys with `POS_counts.items()`.<br>By sorting the list we have access to the tag and its count, in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84. ADJ  : 3\n",
      "85. ADP  : 1\n",
      "90. DET  : 2\n",
      "92. NOUN : 3\n",
      "94. PART : 1\n",
      "97. PUNCT: 1\n",
      "100. VERB : 1\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f'{k}. {doc.vocab[k].text:{5}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74. POS : 1\n",
      "1292078113972184607. IN  : 1\n",
      "10554686591937588953. JJ  : 3\n",
      "12646065887601541794. .   : 1\n",
      "15267657372422890137. DT  : 2\n",
      "15308085513773655218. NN  : 3\n",
      "17109001835818727656. VBD : 1\n"
     ]
    }
   ],
   "source": [
    "# Count the different fine-grained tags:\n",
    "TAG_counts = doc.count_by(spacy.attrs.TAG)\n",
    "\n",
    "for k,v in sorted(TAG_counts.items()):\n",
    "    print(f'{k}. {doc.vocab[k].text:{4}}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">**Why did the ID numbers get so big?** In spaCy, certain text values are hardcoded into `Doc.vocab` and take up the first several hundred ID numbers. Strings like 'NOUN' and 'VERB' are used frequently by internal operations. Others, like fine-grained tags, are assigned hash values as needed.</div>\n",
    "<div class=\"alert alert-success\">**Why don't SPACE tags appear?** In spaCy, only strings of spaces (two or more) are assigned tokens. Single spaces are not.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402. amod: 3\n",
      "415. det : 2\n",
      "429. nsubj: 1\n",
      "439. pobj: 1\n",
      "440. poss: 1\n",
      "443. prep: 1\n",
      "445. punct: 1\n",
      "8110129090154140942. case: 1\n",
      "8206900633647566924. ROOT: 1\n"
     ]
    }
   ],
   "source": [
    "# Count the different dependencies:\n",
    "DEP_counts = doc.count_by(spacy.attrs.DEP)\n",
    "\n",
    "for k,v in sorted(DEP_counts.items()):\n",
    "    print(f'{k}. {doc.vocab[k].text:{4}}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've shown `spacy.attrs.POS`, `spacy.attrs.TAG` and `spacy.attrs.DEP`.<br>Refer back to the **Vocabulary and Matching** lecture from the previous section for a table of **Other token attributes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-grained POS Tag Examples\n",
    "These are some grammatical examples (shown in **bold**) of specific fine-grained tags. We've removed punctuation and rarely used tags:\n",
    "<table>\n",
    "<tr><th>POS</th><th>TAG</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
    "<tr><td>ADJ</td><td>AFX</td><td>affix</td><td>The Flintstones were a **pre**-historic family.</td></tr>\n",
    "<tr><td>ADJ</td><td>JJ</td><td>adjective</td><td>This is a **good** sentence.</td></tr>\n",
    "<tr><td>ADJ</td><td>JJR</td><td>adjective, comparative</td><td>This is a **better** sentence.</td></tr>\n",
    "<tr><td>ADJ</td><td>JJS</td><td>adjective, superlative</td><td>This is the **best** sentence.</td></tr>\n",
    "<tr><td>ADJ</td><td>PDT</td><td>predeterminer</td><td>Waking up is **half** the battle.</td></tr>\n",
    "<tr><td>ADJ</td><td>PRP\\$</td><td>pronoun, possessive</td><td>**His** arm hurts.</td></tr>\n",
    "<tr><td>ADJ</td><td>WDT</td><td>wh-determiner</td><td>It's blue, **which** is odd.</td></tr>\n",
    "<tr><td>ADJ</td><td>WP\\$</td><td>wh-pronoun, possessive</td><td>We don't know **whose** it is.</td></tr>\n",
    "<tr><td>ADP</td><td>IN</td><td>conjunction, subordinating or preposition</td><td>It arrived **in** a box.</td></tr>\n",
    "<tr><td>ADV</td><td>EX</td><td>existential there</td><td>**There** is cake.</td></tr>\n",
    "<tr><td>ADV</td><td>RB</td><td>adverb</td><td>He ran **quickly**.</td></tr>\n",
    "<tr><td>ADV</td><td>RBR</td><td>adverb, comparative</td><td>He ran **quicker**.</td></tr>\n",
    "<tr><td>ADV</td><td>RBS</td><td>adverb, superlative</td><td>He ran **fastest**.</td></tr>\n",
    "<tr><td>ADV</td><td>WRB</td><td>wh-adverb</td><td>**When** was that?</td></tr>\n",
    "<tr><td>CONJ</td><td>CC</td><td>conjunction, coordinating</td><td>The balloon popped **and** everyone jumped.</td></tr>\n",
    "<tr><td>DET</td><td>DT</td><td>determiner</td><td>**This** is **a** sentence.</td></tr>\n",
    "<tr><td>INTJ</td><td>UH</td><td>interjection</td><td>**Um**, I don't know.</td></tr>\n",
    "<tr><td>NOUN</td><td>NN</td><td>noun, singular or mass</td><td>This is a **sentence**.</td></tr>\n",
    "<tr><td>NOUN</td><td>NNS</td><td>noun, plural</td><td>These are **words**.</td></tr>\n",
    "<tr><td>NOUN</td><td>WP</td><td>wh-pronoun, personal</td><td>**Who** was that?</td></tr>\n",
    "<tr><td>NUM</td><td>CD</td><td>cardinal number</td><td>I want **three** things.</td></tr>\n",
    "<tr><td>PART</td><td>POS</td><td>possessive ending</td><td>Fred**'s** name is short.</td></tr>\n",
    "<tr><td>PART</td><td>RP</td><td>adverb, particle</td><td>Put it **back**!</td></tr>\n",
    "<tr><td>PART</td><td>TO</td><td>infinitival to</td><td>I want **to** go.</td></tr>\n",
    "<tr><td>PRON</td><td>PRP</td><td>pronoun, personal</td><td>**I** want **you** to go.</td></tr>\n",
    "<tr><td>PROPN</td><td>NNP</td><td>noun, proper singular</td><td>**Kilroy** was here.</td></tr>\n",
    "<tr><td>PROPN</td><td>NNPS</td><td>noun, proper plural</td><td>The **Flintstones** were a pre-historic family.</td></tr>\n",
    "<tr><td>VERB</td><td>MD</td><td>verb, modal auxiliary</td><td>This **could** work.</td></tr>\n",
    "<tr><td>VERB</td><td>VB</td><td>verb, base form</td><td>I want to **go**.</td></tr>\n",
    "<tr><td>VERB</td><td>VBD</td><td>verb, past tense</td><td>This **was** a sentence.</td></tr>\n",
    "<tr><td>VERB</td><td>VBG</td><td>verb, gerund or present participle</td><td>I am **going**.</td></tr>\n",
    "<tr><td>VERB</td><td>VBN</td><td>verb, past participle</td><td>The treasure was **lost**.</td></tr>\n",
    "<tr><td>VERB</td><td>VBP</td><td>verb, non-3rd person singular present</td><td>I **want** to go.</td></tr>\n",
    "<tr><td>VERB</td><td>VBZ</td><td>verb, 3rd person singular present</td><td>He **wants** to go.</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Parts of Speech\n",
    "spaCy offers an outstanding visualizer called **displaCy**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"2e5a196865874b5295b36e68b6883e1e-0\" class=\"displacy\" width=\"1260\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">jumped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">'s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">back.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e5a196865874b5295b36e68b6883e1e-0-0\" stroke-width=\"2px\" d=\"M70,167.0 C70,2.0 380.0,2.0 380.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e5a196865874b5295b36e68b6883e1e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,169.0 L62,157.0 78,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e5a196865874b5295b36e68b6883e1e-0-1\" stroke-width=\"2px\" d=\"M180,167.0 C180,57.0 375.0,57.0 375.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e5a196865874b5295b36e68b6883e1e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,169.0 L172,157.0 188,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e5a196865874b5295b36e68b6883e1e-0-2\" stroke-width=\"2px\" d=\"M290,167.0 C290,112.0 370.0,112.0 370.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e5a196865874b5295b36e68b6883e1e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,169.0 L282,157.0 298,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e5a196865874b5295b36e68b6883e1e-0-3\" stroke-width=\"2px\" d=\"M400,167.0 C400,112.0 480.0,112.0 480.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e5a196865874b5295b36e68b6883e1e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,169.0 L392,157.0 408,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e5a196865874b5295b36e68b6883e1e-0-4\" stroke-width=\"2px\" d=\"M510,167.0 C510,112.0 590.0,112.0 590.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e5a196865874b5295b36e68b6883e1e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M590.0,169.0 L598.0,157.0 582.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e5a196865874b5295b36e68b6883e1e-0-5\" stroke-width=\"2px\" d=\"M730,167.0 C730,57.0 925.0,57.0 925.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e5a196865874b5295b36e68b6883e1e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730,169.0 L722,157.0 738,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e5a196865874b5295b36e68b6883e1e-0-6\" stroke-width=\"2px\" d=\"M840,167.0 C840,112.0 920.0,112.0 920.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e5a196865874b5295b36e68b6883e1e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,169.0 L832,157.0 848,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e5a196865874b5295b36e68b6883e1e-0-7\" stroke-width=\"2px\" d=\"M950,167.0 C950,57.0 1145.0,57.0 1145.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e5a196865874b5295b36e68b6883e1e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950,169.0 L942,157.0 958,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e5a196865874b5295b36e68b6883e1e-0-8\" stroke-width=\"2px\" d=\"M950,167.0 C950,112.0 1030.0,112.0 1030.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e5a196865874b5295b36e68b6883e1e-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1030.0,169.0 L1038.0,157.0 1022.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e5a196865874b5295b36e68b6883e1e-0-9\" stroke-width=\"2px\" d=\"M620,167.0 C620,2.0 1150.0,2.0 1150.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e5a196865874b5295b36e68b6883e1e-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150.0,169.0 L1158.0,157.0 1142.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Render the dependency parse immediately inside Jupyter:\n",
    "# Import the displaCy library\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 110})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The        DET     det     determiner\n",
      "quick      ADJ     amod    adjectival modifier\n",
      "brown      ADJ     amod    adjectival modifier\n",
      "fox        NOUN    nsubj   nominal subject\n",
      "jumped     VERB    ROOT    root\n",
      "over       ADP     prep    prepositional modifier\n",
      "the        DET     det     determiner\n",
      "lazy       ADJ     amod    adjectival modifier\n",
      "dog        NOUN    poss    possession modifier\n",
      "'s         PART    case    case marking\n",
      "back       NOUN    pobj    object of preposition\n",
      ".          PUNCT   punct   punctuation\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'{token.text:{10}} {token.pos_:{7}} {token.dep_:{7}} {spacy.explain(token.dep_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Visualizations Outside of Jupyter\n",
    "If you're using another Python IDE or writing a script, you can choose to have spaCy serve up HTML separately.\n",
    "\n",
    "Instead of `displacy.render()`, use `displacy.serve()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tazeb\\OneDrive\\AtomicHabit\\LLM Engineering\\venv\\Lib\\site-packages\\spacy\\displacy\\__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"176c4a1da31c4541a9db46468901bbb8-0\" class=\"displacy\" width=\"1260\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">jumped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">'s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">back.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-176c4a1da31c4541a9db46468901bbb8-0-0\" stroke-width=\"2px\" d=\"M70,167.0 C70,2.0 380.0,2.0 380.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-176c4a1da31c4541a9db46468901bbb8-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,169.0 L62,157.0 78,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-176c4a1da31c4541a9db46468901bbb8-0-1\" stroke-width=\"2px\" d=\"M180,167.0 C180,57.0 375.0,57.0 375.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-176c4a1da31c4541a9db46468901bbb8-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,169.0 L172,157.0 188,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-176c4a1da31c4541a9db46468901bbb8-0-2\" stroke-width=\"2px\" d=\"M290,167.0 C290,112.0 370.0,112.0 370.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-176c4a1da31c4541a9db46468901bbb8-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,169.0 L282,157.0 298,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-176c4a1da31c4541a9db46468901bbb8-0-3\" stroke-width=\"2px\" d=\"M400,167.0 C400,112.0 480.0,112.0 480.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-176c4a1da31c4541a9db46468901bbb8-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,169.0 L392,157.0 408,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-176c4a1da31c4541a9db46468901bbb8-0-4\" stroke-width=\"2px\" d=\"M510,167.0 C510,112.0 590.0,112.0 590.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-176c4a1da31c4541a9db46468901bbb8-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M590.0,169.0 L598.0,157.0 582.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-176c4a1da31c4541a9db46468901bbb8-0-5\" stroke-width=\"2px\" d=\"M730,167.0 C730,57.0 925.0,57.0 925.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-176c4a1da31c4541a9db46468901bbb8-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730,169.0 L722,157.0 738,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-176c4a1da31c4541a9db46468901bbb8-0-6\" stroke-width=\"2px\" d=\"M840,167.0 C840,112.0 920.0,112.0 920.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-176c4a1da31c4541a9db46468901bbb8-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,169.0 L832,157.0 848,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-176c4a1da31c4541a9db46468901bbb8-0-7\" stroke-width=\"2px\" d=\"M950,167.0 C950,57.0 1145.0,57.0 1145.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-176c4a1da31c4541a9db46468901bbb8-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950,169.0 L942,157.0 958,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-176c4a1da31c4541a9db46468901bbb8-0-8\" stroke-width=\"2px\" d=\"M950,167.0 C950,112.0 1030.0,112.0 1030.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-176c4a1da31c4541a9db46468901bbb8-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1030.0,169.0 L1038.0,157.0 1022.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-176c4a1da31c4541a9db46468901bbb8-0-9\" stroke-width=\"2px\" d=\"M620,167.0 C620,2.0 1150.0,2.0 1150.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-176c4a1da31c4541a9db46468901bbb8-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150.0,169.0 L1158.0,157.0 1142.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Feb/2025 11:43:58] \"GET / HTTP/1.1\" 200 9180\n",
      "127.0.0.1 - - [12/Feb/2025 11:43:58] \"GET /favicon.ico HTTP/1.1\" 200 9180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "displacy.serve(doc, style='dep', options={'distance': 110})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**After running the cell above, click the link below to view the dependency parse**:</font>\n",
    "\n",
    "http://127.0.0.1:5000\n",
    "<br><br>\n",
    "<font color=red>**To shut down the server and return to jupyter**, interrupt the kernel either through the **Kernel** menu above, by hitting the black square on the toolbar, or by typing the keyboard shortcut `Esc`, `I`, `I`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Large Text\n",
    "`displacy.serve()` accepts a single Doc or list of Doc objects. Since large texts are difficult to view in one line, you may want to pass a list of spans instead. Each span will appear on its own line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"bfd6e00f8f3a4189a2cdb2e8cb51515e-0\" class=\"displacy\" width=\"490\" height=\"247.0\" direction=\"ltr\" style=\"max-width: none; height: 247.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">sentence.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-0-0\" stroke-width=\"2px\" d=\"M70,112.0 C70,57.0 155.0,57.0 155.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,114.0 L62,102.0 78,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-0-1\" stroke-width=\"2px\" d=\"M290,112.0 C290,57.0 375.0,57.0 375.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,114.0 L282,102.0 298,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-0-2\" stroke-width=\"2px\" d=\"M180,112.0 C180,2.0 380.0,2.0 380.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M380.0,114.0 L388.0,102.0 372.0,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"bfd6e00f8f3a4189a2cdb2e8cb51515e-1\" class=\"displacy\" width=\"710\" height=\"247.0\" direction=\"ltr\" style=\"max-width: none; height: 247.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">another,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">possibly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">longer</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">sentence.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-1-0\" stroke-width=\"2px\" d=\"M70,112.0 C70,57.0 155.0,57.0 155.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-1-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,114.0 L62,102.0 78,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-1-1\" stroke-width=\"2px\" d=\"M180,112.0 C180,57.0 265.0,57.0 265.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-1-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M265.0,114.0 L273.0,102.0 257.0,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-1-2\" stroke-width=\"2px\" d=\"M400,112.0 C400,57.0 485.0,57.0 485.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-1-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,114.0 L392,102.0 408,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-1-3\" stroke-width=\"2px\" d=\"M510,112.0 C510,57.0 595.0,57.0 595.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-1-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M510,114.0 L502,102.0 518,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-1-4\" stroke-width=\"2px\" d=\"M180,112.0 C180,2.0 600.0,2.0 600.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bfd6e00f8f3a4189a2cdb2e8cb51515e-1-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M600.0,114.0 L608.0,102.0 592.0,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Feb/2025 11:45:50] \"GET / HTTP/1.1\" 200 8133\n",
      "127.0.0.1 - - [12/Feb/2025 11:45:50] \"GET /favicon.ico HTTP/1.1\" 200 8133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"This is a sentence. This is another, possibly longer sentence.\")\n",
    "\n",
    "# Create spans from Doc.sents:\n",
    "spans = list(doc2.sents)\n",
    "\n",
    "displacy.serve(spans, style='dep', options={'distance': 110})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"62c87ff8212e4e4497b2fd009e7f4f77-0\" class=\"displacy\" width=\"1260\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: yellow; background: #09a3d5; font-family: Times; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">jumped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">'s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">back.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-0\" stroke-width=\"2px\" d=\"M62,167.0 62,112.0 380.0,112.0 380.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,169.0 L58,161.0 66,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-1\" stroke-width=\"2px\" d=\"M172,167.0 172,130.33333333333334 377.0,130.33333333333334 377.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M172,169.0 L168,161.0 176,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-2\" stroke-width=\"2px\" d=\"M282,167.0 282,148.66666666666666 374.0,148.66666666666666 374.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M282,169.0 L278,161.0 286,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-3\" stroke-width=\"2px\" d=\"M392,167.0 392,148.66666666666666 484.0,148.66666666666666 484.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M392,169.0 L388,161.0 396,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-4\" stroke-width=\"2px\" d=\"M502,167.0 502,148.66666666666666 594.0,148.66666666666666 594.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M594.0,169.0 L598.0,161.0 590.0,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-5\" stroke-width=\"2px\" d=\"M722,167.0 722,130.33333333333334 927.0,130.33333333333334 927.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M722,169.0 L718,161.0 726,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-6\" stroke-width=\"2px\" d=\"M832,167.0 832,148.66666666666666 924.0,148.66666666666666 924.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M832,169.0 L828,161.0 836,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-7\" stroke-width=\"2px\" d=\"M942,167.0 942,130.33333333333334 1147.0,130.33333333333334 1147.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M942,169.0 L938,161.0 946,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-8\" stroke-width=\"2px\" d=\"M942,167.0 942,148.66666666666666 1034.0,148.66666666666666 1034.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1034.0,169.0 L1038.0,161.0 1030.0,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-9\" stroke-width=\"2px\" d=\"M612,167.0 612,112.0 1150.0,112.0 1150.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-62c87ff8212e4e4497b2fd009e7f4f77-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150.0,169.0 L1154.0,161.0 1146.0,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Feb/2025 11:46:23] \"GET / HTTP/1.1\" 200 9391\n",
      "127.0.0.1 - - [12/Feb/2025 11:46:23] \"GET /favicon.ico HTTP/1.1\" 200 9391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "options = {'distance': 110, 'compact': 'True', 'color': 'yellow', 'bg': '#09a3d5', 'font': 'Times'}\n",
    "\n",
    "displacy.serve(doc, style='dep', options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Named Entity Recognition (NER) in spaCy\n",
    "\n",
    "For more on **Named Entity Recognition** visit https://spacy.io/usage/linguistic-features#101\n",
    "\n",
    "\n",
    "In **spaCy**, **Named Entity Recognition (NER)** is a process that identifies and classifies entities in text, such as names, organizations, dates, and locations. The **`ner`** component in spaCy‚Äôs pipeline is responsible for detecting these entities based on pre-trained models.\n",
    "\n",
    "#### üîπ How to Access Named Entities:\n",
    "- `token.ent_type_` ‚Üí Entity type of a token.\n",
    "- `ent.text` ‚Üí Extracted entity text.\n",
    "- `ent.label_` ‚Üí Entity label (e.g., `PERSON`, `ORG`, `DATE`).\n",
    "- `spacy.explain(ent.label_)` ‚Üí Get explanations for entity labels.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"John works at Google and lives in New York.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"‚Üí\", ent.label_, \"(\", spacy.explain(ent.label_), \")\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üåê **Semantic Analysis in NLP**\n",
    "\n",
    "**Semantic Analysis** is the process of understanding the **meaning and relationships** between words, phrases, and sentences in context.  \n",
    "It goes beyond **syntactic structure** to capture **the intent, roles, and interactions** of words within text.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç **Key Techniques in Semantic Analysis**\n",
    "\n",
    "1. **Word Sense Disambiguation (WSD)** ‚Äì Identify the correct meaning of words with multiple senses.  \n",
    "2. **Named Entity Recognition (NER)** ‚Äì Recognize proper names (people, organizations, etc.).  \n",
    "3. **Semantic Role Labeling (SRL)** ‚Äì Determine who did what to whom, when, and how.  \n",
    "4. **Relation Extraction** ‚Äì Identify relationships between entities.  \n",
    "5. **Coreference Resolution** ‚Äì Link pronouns to the correct entities.\n",
    "\n",
    "---\n",
    "\n",
    "#### üõ†Ô∏è **Python Code Example: Semantic Analysis with spaCy**\n",
    "\n",
    "#### **Problem:** Analyze the semantic structure of the following sentence:  \n",
    "*\"John gave Mary a beautiful gift on her birthday.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "            print(ent.text + ' -- is label--> ' + ent.label_ + ' --- EXPLAIN--> ' + str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington, DC - GPE - Countries, cities, states\n",
      "next May - DATE - Absolute or relative dates or periods\n",
      "the Washington Monument - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "# Write a function to display basic entity info:\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text + ' - ' + ent.label_ + ' - ' + str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No named entities found.')\n",
    "\n",
    "doc = nlp(u'May I go to Washington, DC next May to see the Washington Monument?')\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see tokens combine to form the entities Washington, DC, next May and the Washington Monument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entity annotations\n",
    "`Doc.ents` are token spans with their own set of annotations.\n",
    "<table>\n",
    "<tr><td>`ent.text`</td><td>The original entity text</td></tr>\n",
    "<tr><td>`ent.label`</td><td>The entity type's hash value</td></tr>\n",
    "<tr><td>`ent.label_`</td><td>The entity type's string description</td></tr>\n",
    "<tr><td>`ent.start`</td><td>The token span's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end`</td><td>The token span's *stop* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.start_char`</td><td>The entity text's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end_char`</td><td>The entity text's *stop* index position in the Doc</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NER Tags\n",
    "Tags are accessible through the `.label_` property of an entity.\n",
    "<table>\n",
    "<tr><th>TYPE</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
    "<tr><td>`PERSON`</td><td>People, including fictional.</td><td>*Fred Flintstone*</td></tr>\n",
    "<tr><td>`NORP`</td><td>Nationalities or religious or political groups.</td><td>*The Republican Party*</td></tr>\n",
    "<tr><td>`FAC`</td><td>Buildings, airports, highways, bridges, etc.</td><td>*Logan International Airport, The Golden Gate*</td></tr>\n",
    "<tr><td>`ORG`</td><td>Companies, agencies, institutions, etc.</td><td>*Microsoft, FBI, MIT*</td></tr>\n",
    "<tr><td>`GPE`</td><td>Countries, cities, states.</td><td>*France, UAR, Chicago, Idaho*</td></tr>\n",
    "<tr><td>`LOC`</td><td>Non-GPE locations, mountain ranges, bodies of water.</td><td>*Europe, Nile River, Midwest*</td></tr>\n",
    "<tr><td>`PRODUCT`</td><td>Objects, vehicles, foods, etc. (Not services.)</td><td>*Formula 1*</td></tr>\n",
    "<tr><td>`EVENT`</td><td>Named hurricanes, battles, wars, sports events, etc.</td><td>*Olympic Games*</td></tr>\n",
    "<tr><td>`WORK_OF_ART`</td><td>Titles of books, songs, etc.</td><td>*The Mona Lisa*</td></tr>\n",
    "<tr><td>`LAW`</td><td>Named documents made into laws.</td><td>*Roe v. Wade*</td></tr>\n",
    "<tr><td>`LANGUAGE`</td><td>Any named language.</td><td>*English*</td></tr>\n",
    "<tr><td>`DATE`</td><td>Absolute or relative dates or periods.</td><td>*20 July 1969*</td></tr>\n",
    "<tr><td>`TIME`</td><td>Times smaller than a day.</td><td>*Four hours*</td></tr>\n",
    "<tr><td>`PERCENT`</td><td>Percentage, including \"%\".</td><td>*Eighty percent*</td></tr>\n",
    "<tr><td>`MONEY`</td><td>Monetary values, including unit.</td><td>*Twenty Cents*</td></tr>\n",
    "<tr><td>`QUANTITY`</td><td>Measurements, as of weight or distance.</td><td>*Several kilometers, 55kg*</td></tr>\n",
    "<tr><td>`ORDINAL`</td><td>\"first\", \"second\", etc.</td><td>*9th, Ninth*</td></tr>\n",
    "<tr><td>`CARDINAL`</td><td>Numerals that do not fall under another type.</td><td>*2, Two, Fifty-two*</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a Named Entity to a Span\n",
    "Normally we would have spaCy build a library of named entities by training it on several samples of text.<br>In this case, we only want to add one value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.K. - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Tesla to build a U.K. factory for $6 million')\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "# Get the hash value of the ORG entity label\n",
    "ORG = doc.vocab.strings[u'ORG'] \n",
    "\n",
    "# Create a Span for the new entity\n",
    "new_ent = Span(doc, 0, 1, label=ORG)\n",
    "\n",
    "# Add the entity to the existing Doc object\n",
    "doc.ents = list(doc.ents) + [new_ent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>In the code above, the arguments passed to `Span()` are:</font>\n",
    "-  `doc` - the name of the Doc object\n",
    "-  `0` - the *start* index position of the span\n",
    "-  `1` - the *stop* index position (exclusive)\n",
    "-  `label=ORG` - the label assigned to our entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla - ORG - Companies, agencies, institutions, etc.\n",
      "U.K. - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Named Entities to All Matching Spans\n",
    "What if we want to tag *all* occurrences of \"Tesla\"? In this section we show how to use the PhraseMatcher to identify a series of spans in the Doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first - ORDINAL - \"first\", \"second\", etc.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Our company plans to introduce a new vacuum cleaner. '\n",
    "          u'If successful, the vacuum cleaner will be our first product.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PhraseMatcher and create a matcher object:\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the desired phrase patterns:\n",
    "phrase_list = ['vacuum cleaner', 'vacuum-cleaner']\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2689272359382549672, 7, 9), (2689272359382549672, 14, 16)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the patterns to our matcher object:\n",
    "matcher.add('newproduct', None, *phrase_patterns)\n",
    "\n",
    "# Apply the matcher to our Doc object:\n",
    "matches = matcher(doc)\n",
    "\n",
    "# See what matches occur:\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create Spans from each match, and create named entities from them:\n",
    "from spacy.tokens import Span\n",
    "\n",
    "PROD = doc.vocab.strings[u'PRODUCT']\n",
    "new_ents = [Span(doc, match[1], match[2], label=PROD) for match in matches]\n",
    "doc.ents = list(doc.ents) + new_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "first - ORDINAL - \"first\", \"second\", etc.\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting Entities\n",
    "While spaCy may not have a built-in tool for counting entities, we can pass a conditional statement into a list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.50 - MONEY - Monetary values, including unit\n",
      "five dollars - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Originally priced at $29.50, the sweater was marked down to five dollars.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ent for ent in doc.ents if ent.label_=='MONEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.50 - MONEY - Monetary values, including unit\n",
      "five dollars - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Originally priced at $29.50,\\nthe sweater was marked down to five dollars.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>However, there is a simple fix that can be added to the nlp pipeline:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John Doe', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "from spacy.language import Language\n",
    "\n",
    "# Custom function to remove whitespace-only entities\n",
    "@Language.component(\"remove_whitespace_entities\")\n",
    "def remove_whitespace_entities(doc):\n",
    "    doc.ents = [e for e in doc.ents if not e.text.isspace()]\n",
    "    return doc\n",
    "\n",
    "# Register and insert the function AFTER 'ner'\n",
    "nlp.add_pipe(\"remove_whitespace_entities\", after='ner')\n",
    "\n",
    "# Test the pipeline\n",
    "doc = nlp(\"John Doe is   \")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])  # Should return non-whitespace entities only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.50 - MONEY - Monetary values, including unit\n",
      "five dollars - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "# Rerun nlp on the text above, and show ents:\n",
    "doc = nlp(u'Originally priced at $29.50,\\nthe sweater was marked down to five dollars.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars - cars - nsubj - shift\n",
      "insurance liability - liability - dobj - shift\n",
      "manufacturers - manufacturers - pobj - toward\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text+' - '+chunk.root.text+' - '+chunk.root.dep_+' - '+chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Doc.noun_chunks` is a  generator function\n",
    "Previously we mentioned that `Doc` objects do not retain a list of sentences, but they're available through the `Doc.sents` generator.<br>It's the same with `Doc.noun_chunks` - lists can be created if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(doc.noun_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on **noun_chunks** visit https://spacy.io/usage/linguistic-features#noun-chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " iPods for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ". By contrast, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sony\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    only 7 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " Walkman music players.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million. '\n",
    "         u'By contrast, Sony sold only 7 thousand Walkman music players.')\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing Sentences Line by Line\n",
    "Unlike the **displaCy** dependency parse, the NER viewer has to take in a Doc object with an `ents` attribute. For this reason, we can't just pass a list of spans to `.render()`, we have to create a new Doc from each `span.text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " iPods for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">By contrast, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sony\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    only 7 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " Walkman music players.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    displacy.render(nlp(sent.text), style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: If a span does not contain any entities, displaCy will issue a harmless warning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " iPods for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tazeb\\OneDrive\\AtomicHabit\\LLM Engineering\\venv\\Lib\\site-packages\\spacy\\displacy\\__init__.py:213: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">By contrast, my kids sold a lot of lemonade.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc2 = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million. '\n",
    "         u'By contrast, my kids sold a lot of lemonade.')\n",
    "\n",
    "for sent in doc2.sents:\n",
    "    displacy.render(nlp(sent.text), style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " iPods for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By contrast, my kids sold a lot of lemonade.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc2.sents:\n",
    "    docx = nlp(sent.text)\n",
    "    if docx.ents:\n",
    "        displacy.render(docx, style='ent', jupyter=True)\n",
    "    else:\n",
    "        print(docx.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customizing Colors and Effects\n",
    "You can also pass background color and gradient options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over the last quarter \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold nearly 20 thousand iPods for a profit of $6 million. By contrast, \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sony\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold only 7 thousand Walkman music players.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {'ORG': 'linear-gradient(90deg, #aa9cfc, #fc9ce7)', 'PRODUCT': 'radial-gradient(yellow, green)'}\n",
    "\n",
    "options = {'ents': ['ORG', 'PRODUCT'], 'colors':colors}\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on applying CSS background colors and gradients, visit https://www.w3schools.com/css/css3_gradients.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Visualizations Outside of Jupyter\n",
    "If you're using another Python IDE or writing a script, you can choose to have spaCy serve up HTML separately.\n",
    "\n",
    "Instead of `displacy.render()`, use `displacy.serve()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Tokenizer\n",
    "The first step in processing text is to split up all the component parts (words & punctuation) into \"tokens\". These tokens are annotated inside the Doc object to contain descriptive information. We'll go into much more detail on tokenization in an upcoming lecture. For now, let's look at another example:\n",
    "\n",
    "\n",
    "#### Additional Token Attributes\n",
    "We'll see these again in upcoming lectures. For now we just want to illustrate some of the other information that spaCy assigns to tokens:\n",
    "\n",
    "\n",
    "|Tag|Description|doc2[0].tag|\n",
    "|:------|:------:|:------|\n",
    "|`.text`|The original word text<!-- .element: style=\"text-align:left;\" -->|`Tesla`|\n",
    "|`.lemma_`|The base form of the word|`tesla`|\n",
    "|`.pos_`|The simple part-of-speech tag|`PROPN`/`proper noun`|\n",
    "|`.tag_`|The detailed part-of-speech tag|`NNP`/`noun, proper singular`|\n",
    "|`.shape_`|The word shape ‚Äì capitalization, punctuation, digits|`Xxxxx`|\n",
    "|`.is_alpha`|Is the token an alpha character?|`True`|\n",
    "|`.is_stop`|Is the token part of a stop list, i.e. the most common words of the language?|`False`|\n",
    "\n",
    "\n",
    "-  **Prefix**:\tCharacter(s) at the beginning &#9656; `$ ( ‚Äú ¬ø`\n",
    "-  **Suffix**:\tCharacter(s) at the end &#9656; `km ) , . ! ‚Äù`\n",
    "-  **Infix**:\tCharacter(s) in between &#9656; `- -- / ...`\n",
    "-  **Exception**: Special-case rule to split a string into several tokens or prevent a token from being split when punctuation rules are applied &#9656; `St. U.S.`\n",
    "\n",
    "Notice that tokens are pieces of the original text. That is, we don't see any conversion to word stems or lemmas (base forms of words) and we haven't seen anything about organizations/places/money etc. Tokens are the basic building blocks of a Doc object - everything that helps us understand the meaning of the text is derived from tokens and their relationship to one another.\n",
    "\n",
    "#### Prefixes, Suffixes and Infixes\n",
    "spaCy will isolate punctuation that does *not* form an integral part of a word. Quotation marks, commas, and punctuation at the end of a sentence will be assigned their own token. However, punctuation that exists as part of an email address, website or numerical value will be kept as part of the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n",
      "\" | We | 're | moving | to | L.A. | ! | \" | "
     ]
    }
   ],
   "source": [
    "mystring = '\"We\\'re moving to L.A.!\"'\n",
    "print(mystring)\n",
    "doc = nlp(mystring)\n",
    "for token in doc:    \n",
    "    print(token.text, end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Token: 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Token: {len(doc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spans:** Large Doc objects can be hard to work with at times. A span is a slice of Doc object in the form Doc[start:stop]\n",
    "\n",
    "In upcoming lectures we'll see how to create Span objects using Span(). This will allow us to assign additional information to the Span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_quote = doc[4:10]\n",
    "print(f\"spans/Slice {life_quote}\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 4 üõ†Ô∏è **Lemmatization vs Stemming in NLP**\n",
    "\n",
    "Both **lemmatization** and **stemming** are text normalization techniques used to reduce words to their base or root forms, which helps in **improving text analysis** by treating different forms of the same word as identical.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîç **1Ô∏è‚É£ Lemmatization**\n",
    "\n",
    "**Lemmatization** reduces a word to its **base or dictionary form (lemma)** based on its **meaning and context**. It requires a vocabulary and **morphological analysis** of the word.  \n",
    "- **Tool in spaCy:** `token.lemma_`\n",
    "\n",
    "**Example:**  \n",
    "- `running` ‚Üí `run`  \n",
    "- `better` ‚Üí `good`  \n",
    "- `studies` ‚Üí `study`  \n",
    "\n",
    "**Key Characteristics:**  \n",
    "- **Context-aware** (depends on POS tags)  \n",
    "- **Slower but more accurate**  \n",
    "- Requires a language model (e.g., `en_core_web_sm` in spaCy)  \n",
    "\n",
    "**spaCy Example:**  \n",
    "```python\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"He is running and studies hard.\")\n",
    "print([(token.text, token.lemma_) for token in doc])\n",
    "```\n",
    "\n",
    "#### üå± **Stemming in NLP**\n",
    "\n",
    "**Stemming** is a text preprocessing technique used in **Natural Language Processing (NLP)** to reduce words to their **root form** by **removing prefixes or suffixes**. It applies **rule-based algorithms** without considering the word's **context or meaning**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîç **How Stemming Works**\n",
    "\n",
    "Stemming works by applying **linguistic heuristics** to cut off **affixes** like **-ing**, **-ed**, **-s**, and **-ly** to find the **stem** of a word.  \n",
    "- It does **not guarantee a valid word** but helps in **text normalization** for tasks like **information retrieval**.\n",
    "\n",
    "##### **Examples:**\n",
    "- `running` ‚Üí `run`  \n",
    "- `studies` ‚Üí `studi` *(not a valid word)*  \n",
    "- `better` ‚Üí `better` *(no change as it doesn't follow simple rules)*  \n",
    "\n",
    "---\n",
    "\n",
    "##### üß† **Popular Stemming Algorithms**\n",
    "\n",
    "1. **Porter Stemmer** (widely used and efficient for English)  \n",
    "2. **Snowball Stemmer** (an improved version of Porter)  \n",
    "3. **Lancaster Stemmer** (more aggressive and less accurate)  \n",
    "\n",
    "---\n",
    "\n",
    "##### ‚öôÔ∏è **Python Code Examples**\n",
    "\n",
    "##### 1Ô∏è‚É£ **Porter Stemmer**\n",
    "```python\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "words = [\"running\", \"played\", \"flies\", \"studies\", \"better\"]\n",
    "print([stemmer.stem(word) for word in words])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ‚Üí the\n",
      "cats ‚Üí cat\n",
      "are ‚Üí be\n",
      "running ‚Üí run\n",
      "faster ‚Üí fast\n",
      "than ‚Üí than\n",
      "the ‚Üí the\n",
      "mice ‚Üí mouse\n",
      ", ‚Üí ,\n",
      "while ‚Üí while\n",
      "John ‚Üí John\n",
      "was ‚Üí be\n",
      "studying ‚Üí study\n",
      "hard ‚Üí hard\n",
      "for ‚Üí for\n",
      "his ‚Üí his\n",
      "exams ‚Üí exam\n",
      ". ‚Üí .\n"
     ]
    }
   ],
   "source": [
    "# Sample text for lemmatization\n",
    "text = \"The cats are running faster than the mice, while John was studying hard for his exams.\"\n",
    "\n",
    "# Process the text through spaCy's pipeline\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print each word with its lemma\n",
    "for token in doc:\n",
    "    print(f\"{token.text} ‚Üí {token.lemma_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 4690420944186131903 \t I\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "because \t SCONJ \t 16950148841647037698 \t because\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "run \t VERB \t 12767647472892411841 \t run\n",
      "since \t SCONJ \t 10066841407251338481 \t since\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      "today \t NOUN \t 11042482332948150395 \t today\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(u\"I am a runner running in a race because I love to run since I ran today\")\n",
    "\n",
    "for token in doc1:\n",
    "    print(token.text, '\\t', token.pos_, '\\t', token.lemma, '\\t', token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>In the above sentence, `running`, `run` and `ran` all point to the same lemma `run` (...11841) to avoid duplication.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Parser\n",
    "\n",
    "### üîç **Dependency Parser in NLP (spaCy)**\n",
    "\n",
    "**Parser** in NLP refers to the **Dependency Parser**, which analyzes the **grammatical structure** of a sentence.  \n",
    "It determines the **relationships between words** by assigning each word a **syntactic role** (e.g., subject, object, modifier) and connecting them in a **dependency tree**.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è **What Does the Parser Do?**\n",
    "\n",
    "1. **Identifies syntactic dependencies** (e.g., subject, object, modifier).  \n",
    "2. **Builds a dependency tree** to represent sentence structure.  \n",
    "3. **Helps with relation extraction** (e.g., who did what to whom).  \n",
    "4. **Supports downstream tasks** like **Named Entity Recognition (NER)**, **coreference resolution**, and **text generation**.\n",
    "\n",
    "---\n",
    "\n",
    "## üå≤ **Dependency Parser in Action (spaCy)**\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample sentence\n",
    "text = \"John gave Mary a beautiful gift.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the dependency information\n",
    "print(f\"{'Token':<10} {'Dependency':<15} {'Head':<10} {'Children'}\")\n",
    "print(\"-\" * 50)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<10} {token.dep_:<15} {token.head.text:<10} {[child.text for child in token.children]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token      Dependency      Head       Children\n",
      "--------------------------------------------------\n",
      "John       nsubj           gave       []\n",
      "gave       ROOT            gave       ['John', 'Mary', 'gift', '.']\n",
      "Mary       dative          gave       []\n",
      "a          det             gift       []\n",
      "beautiful  amod            gift       []\n",
      "gift       dobj            gave       ['a', 'beautiful']\n",
      ".          punct           gave       []\n"
     ]
    }
   ],
   "source": [
    "# Sample sentence\n",
    "text = \"John gave Mary a beautiful gift.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the dependency information\n",
    "print(f\"{'Token':<10} {'Dependency':<15} {'Head':<10} {'Children'}\")\n",
    "print(\"-\" * 50)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<10} {token.dep_:<15} {token.head.text:<10} {[child.text for child in token.children]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applications of Dependency Parsing**\n",
    "- Relation Extraction: Extract relationships from text (e.g., subject, object).\n",
    "- Text Summarization: Identify key components in sentences.\n",
    "- Sentiment Analysis: Analyze how words relate to each other.\n",
    "- Question Answering Systems: Understand sentence structure for better response generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Text Classification\n",
    "\n",
    "##### üß† **Text Classification in spaCy**\n",
    "\n",
    "**Text Classification** is the process of **categorizing text into predefined labels**.  \n",
    "In **spaCy**, the **`textcat` component** is responsible for **text classification** tasks like **sentiment analysis**, **topic detection**, **spam filtering**, and more.\n",
    "\n",
    "---\n",
    "\n",
    "##### üîç **How Does Text Classification Work in spaCy?**\n",
    "\n",
    "1. **Tokenization:** The text is broken into tokens.  \n",
    "2. **Feature Extraction:** Relevant linguistic features are extracted.  \n",
    "3. **Model Training:** A statistical or transformer-based model learns from labeled data.  \n",
    "4. **Prediction:** The model assigns **one or more labels** to unseen text.\n",
    "\n",
    "---\n",
    "\n",
    "##### ‚öôÔ∏è **Text Classification Modes**\n",
    "\n",
    "spaCy supports two types of text classification:  \n",
    "\n",
    "1. **Single-label classification**: Each text is assigned exactly **one label**.  \n",
    "   *(e.g., **`positive`** or **`negative`` sentiment)*  \n",
    "\n",
    "2. **Multi-label classification**: Each text can be assigned **multiple labels**.  \n",
    "   *(e.g., a news article can be both **`politics`** and **`economy`**)*  \n",
    "\n",
    "---\n",
    "\n",
    "##### üõ†Ô∏è **Python Code Example: Text Classification with spaCy**\n",
    "\n",
    "###### **üîπ Task:** Classify text as **Positive**, **Negative**, or **Neutral**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
